# FinSage: AI-Powered Financial Research Report Generator

An end-to-end automated system that generates professional financial research reports for U.S. public companies using Large Language Models, multi-agent architecture, and modern data engineering tools.

## Problem Statement

Investment decisions worth billions of dollars depend on high-quality financial research reports. However, producing these reports is:

- **Labor-intensive**: Analysts spend weeks gathering data from multiple sources
- **Time-consuming**: Manual analysis of financial statements, news, and market data
- **Expensive**: Professional reports cost thousands of dollars
- **Inconsistent**: Quality varies based on analyst expertise

**FinSage automates this process**, generating 15-20 page professional financial reports with charts, analysis, and citations in under 30 minutes.

## Solution Overview

FinSage implements a three-stage pipeline:

1. **Data Collection**: Gathers heterogeneous data from Yahoo Finance, NewsAPI, and financial databases
2. **Data Analysis**: Uses multi-agent architecture with Code Agent Variable Memory (CAVM) for dynamic analysis
3. **Report Generation**: Produces formatted reports with visualizations using two-stage writing framework

## Technology Stack

### Data Engineering

- **Snowflake**: Cloud data warehouse for scalable storage and compute
- **dbt (Data Build Tool)**: SQL-based transformations with built-in testing
- **Apache Airflow**: Workflow orchestration and scheduling (planned)
- **Snowpark Python**: In-database Python execution

### Data Sources

- **Yahoo Finance API**: Daily stock prices (OHLCV data)
- **NewsAPI**: Financial news articles and sentiment
- **Alpha Vantage**: Company fundamentals (revenue, earnings, ratios)

### AI/ML

- **Snowflake Cortex LLM**: Built-in language models for analysis
- **GPT-4 Vision**: Chart quality refinement (planned)
- **Cortex Search**: Vector embeddings for semantic retrieval (planned)

### Development Tools

- **Python 3.13**: Core programming language
- **pandas**: Data manipulation
- **Git/GitHub**: Version control
- **dotenv**: Secure credential management

## Architecture

```

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ DATA COLLECTION LAYER â”‚
â”‚ Yahoo Finance | NewsAPI | Alpha Vantage â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ RAW LAYER (Snowflake) â”‚
â”‚ raw_stock_prices | raw_fundamentals â”‚
â”‚ raw_news â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STAGING LAYER (dbt transformations) â”‚
â”‚ stg_stock_prices | stg_fundamentals â”‚
â”‚ stg_news (with sentiment) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ANALYTICS LAYER (planned) â”‚
â”‚ Financial metrics | Growth calculations â”‚
â”‚ Comparative analysis â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ REPORT GENERATION (planned) â”‚
â”‚ Multi-page PDF with charts & citations â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

```

## Key Features Implemented

### Production-Grade Data Pipeline

- **Idempotent Loading**: MERGE statements prevent duplicate data
- **Data Quality Validation**: Pre-load checks for data integrity
- **Quality Scoring**: 0-100 score tracking data completeness
- **Incremental Loading**: Only fetches new data since last run

### Data Transformation

- **Automated dbt Models**: SQL-based transformations with dependency management
- **Parallel Execution**: 4-thread concurrency for faster processing
- **Built-in Testing**: Automated validation of data quality rules

### Security & Best Practices

- Environment variable management for API keys
- Structured logging and error handling
- Git version control with proper .gitignore
- Modular code organization

## Project Structure

```

finsage-project/
â”œâ”€â”€ .env # Credentials (not in Git)
â”œâ”€â”€ .gitignore
â”œâ”€â”€ README.md
â”œâ”€â”€ schema*design.md # Database schema documentation
â”œâ”€â”€ scripts/ # Python scripts
â”‚ â”œâ”€â”€ snowflake_connection.py
â”‚ â”œâ”€â”€ load_sample_stock_data.py
â”‚ â”œâ”€â”€ load_sample_fundamentals.py
â”‚ â”œâ”€â”€ load_sample_news.py
â”‚ â”œâ”€â”€ verify*_.py # Data verification scripts
â”‚ â””â”€â”€ run*migration*_.py # Database migrations
â”œâ”€â”€ sql/ # SQL DDL scripts
â”‚ â”œâ”€â”€ 01_create_raw_schema.sql
â”‚ â”œâ”€â”€ 02_add_quality_score_column.sql
â”‚ â””â”€â”€ 05_create_staging_schema.sql
â”œâ”€â”€ dbt_finsage/ # dbt project
â”‚ â”œâ”€â”€ dbt_project.yml
â”‚ â””â”€â”€ models/
â”‚ â””â”€â”€ staging/
â”‚ â”œâ”€â”€ stg_stock_prices.sql
â”‚ â”œâ”€â”€ stg_fundamentals.sql
â”‚ â”œâ”€â”€ stg_news.sql
â”‚ â””â”€â”€ schema.yml
â””â”€â”€ notebooks/ # Jupyter notebooks (planned)

```

## Setup Instructions

### Prerequisites

- Python 3.13+
- Snowflake account (academic or trial)
- API keys: NewsAPI, Alpha Vantage (optional)

### Installation

1. **Clone the repository**

```bash
git clone <your-repo-url>
cd finsage-project
```

2. **Create virtual environment**

```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

3. **Install dependencies**

```bash
pip install snowflake-snowpark-python yfinance pandas httpx beautifulsoup4 python-dotenv dbt-snowflake
```

4. **Configure credentials**

Create `.env` file in project root:

```
SNOWFLAKE_ACCOUNT=your_account
SNOWFLAKE_USER=your_username
SNOWFLAKE_PASSWORD=your_password
SNOWFLAKE_ROLE=your_role
SNOWFLAKE_WAREHOUSE=your_warehouse
SNOWFLAKE_DATABASE=FINSAGE_DB
SNOWFLAKE_SCHEMA=RAW
NEWSAPI_KEY=your_newsapi_key
```

5. **Initialize database**

```bash
python scripts/create_raw_schema.py
python scripts/run_migration_05.py
```

6. **Initialize dbt**

```bash
cd dbt_finsage
dbt debug  # Verify connection
dbt run    # Run all models
dbt test   # Run data quality tests
```

### Running the Pipeline

**Load data:**

```bash
python scripts/load_sample_stock_data.py
python scripts/load_sample_fundamentals.py
python scripts/load_sample_news.py
```

**Transform data:**

```bash
cd dbt_finsage
dbt run --select staging
dbt test --select staging
```

**Verify results:**

```bash
python scripts/verify_staging_stock.py
```

## Current Progress

**Completed (Week 1-2):**

- âœ… Environment setup and Snowflake connection
- âœ… RAW layer with 3 data sources
- âœ… Production-grade loading (idempotency, quality checks, incremental)
- âœ… dbt project with 3 staging models
- âœ… Automated data quality testing

**In Progress (Week 3):**

- ğŸ”„ Analytics layer (financial metrics calculations)
- ğŸ”„ CAVM architecture implementation

**Planned (Week 4-8):**

- ğŸ“‹ Chart generation with iterative VLM refinement
- ğŸ“‹ Chain-of-Analysis (CoA) generation
- ğŸ“‹ Two-stage report writing framework
- ğŸ“‹ Airflow DAG orchestration
- ğŸ“‹ PDF report generation

**Progress: ~20% complete**

Key innovations being implemented:

- **CAVM Architecture**: Unified programmable workspace for data, tools, and agents
- **Iterative Vision-Enhanced Mechanism**: Chart quality improvement using VLM feedback
- **Two-Stage Writing**: CoA generation followed by report composition

## Why These Tools?

**Snowflake**: Industry-standard cloud data warehouse with native AI capabilities (Cortex)

**dbt**: Transforms data engineering into software engineering with version control, testing, and documentation

**Airflow**: Production-grade orchestration used by Airbnb, Twitter, and thousands of companies

**Python**: Versatile language with rich ecosystem for data engineering and AI

## Team

Graduate students at Northeastern University
Course: DAMG 7374 - Data Engineering: Impact of Generative AI with LLMs

## License

MIT License

## Contact

For questions or collaboration: [shantharajamani.r@northeastern.edu](mailto:shantharajamani.r@northeastern.edu) | [misra.o@northeastern.edu](mailto:misra.o@northeastern.edu) | [vedanarayanan.s@northeastern.edu](mailto:vedanarayanan.s@northeastern.edu)

---

**Note**: This is an academic project demonstrating modern data engineering practices with LLMs. Not intended for actual investment decisions.

```

```
